{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to become a snarXiv master\n",
    "\n",
    "**Background**  \n",
    "The [snarXiv-vs-arXiv](http://snarxiv.org/vs-arxiv/) website challenges you to tell fake physics research articles from real ones. Real paper titles are taken from [arXiv](https://arxiv.org/) whereas fake titles are produced by a so-called *context-free grammar*, the code if freely available ([link](https://github.com/davidsd/snarxiv)). \n",
    "\n",
    "<img src=\"pics/arxiv_vs_snarxiv_logo.png\" width=300>\n",
    "\n",
    "**Aim**  \n",
    "Develop a supervised learning algorithm to correctly classify arXiv/snarXiv.\n",
    "\n",
    "**Method**  \n",
    "- scrape a number of articles using selenium, get the correct labels from randomly clicking arXiv/snarXiv and parsing the result and save this dataset for training/testing\n",
    "- use natural-language processing (NLP) to transform the paper titles into a bag-of-words (BOW) model\n",
    "- train and optimize a range of classifiers\n",
    "- testing: apply the learned classifier to the snarXiv website\n",
    "\n",
    "**Results**  \n",
    "- classifiers reach around 80% accuracy\n",
    "- side effect: develop a 100% accuracy full-cheat mode by parsing the correct answer before submitting, snarXiv will classify you as Nobel Prize level in turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a training data set (*optional*)\n",
    "\n",
    "This step is optional as there is a training data set provided for you.  \n",
    "The function below uses [Selenium](https://www.selenium.dev/documentation/) to scrape a number `2*n_total` of titles from http://snarxiv.org/vs-arxiv/, always clicks the left one and parses the website's answer to get the correct label for that title. The results are stored in a Python dictionary (and optionally written to a file). Thus, you should get approximately `n_total` arXiv and `n_total` snarXiv samples.  \n",
    "\n",
    "**Note**: Selenium needs the webdriver file. I get my Firefox geckodriver from https://github.com/mozilla/geckodriver/releases. More info at: https://github.com/mozilla/geckodriver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def download(n_total=10, verbose=False):\n",
    "    \"\"\"\n",
    "    Download 2n samples from: http://snarxiv.org/vs-arxiv\"\n",
    "    \"\"\"\n",
    "    options = webdriver.FirefoxOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument('--ignore-certificate-errors')\n",
    "    options.add_argument(\"--test-type\")\n",
    "    profile = webdriver.FirefoxProfile()\n",
    "    br = webdriver.Firefox(profile)\n",
    "    br.get(\"http://snarxiv.org/vs-arxiv\")\n",
    "\n",
    "    n = 0 # counter\n",
    "    n_correct = nc = 0 # current number of correct answers\n",
    "    real_titles = []\n",
    "    fake_titles = []\n",
    "    while n <= n_total:\n",
    "        if verbose: print(f\"[+] Trial: {n:d}/{n_total:d}\")\n",
    "        # get DOM elements\n",
    "        c0 = br.find_element_by_class_name('corner-0')\n",
    "        h0 = c0.find_element_by_tag_name('h1')\n",
    "        a0 = h0.find_element_by_tag_name('a')\n",
    "        txt0 = a0.text.replace(\"Is this one real?\", \"\") # left title\n",
    "        c1 = br.find_element_by_class_name('corner-1')\n",
    "        h1 = c1.find_element_by_tag_name('h1')\n",
    "        a1 = h1.find_element_by_tag_name('a')\n",
    "        txt1 = a1.text.replace(\"Is this one real?\", \"\") # right title\n",
    "        # always click left and parse true/false (arXiv/snarXiv) from the updated score\n",
    "        a0.click()\n",
    "        # number of correct guesses\n",
    "        if n > 0:\n",
    "            # DOM element indicating the current number of correct answers\n",
    "            s_nc = br.find_element_by_id('correct').text\n",
    "            try:\n",
    "                nc = int(s_nc) # string => int\n",
    "                if nc > n_correct:\n",
    "                    # latest answer was correct\n",
    "                    if verbose: print(f\"\\tcorrect (nc = {nc:d})\")\n",
    "                    n_correct = nc # update n_correct\n",
    "                    real_titles.append(txt0) # left: correct\n",
    "                    fake_titles.append(txt1) # right: wrong\n",
    "                else:\n",
    "                    # latest answer was not correct\n",
    "                    if verbose: print(f\"\\twrong (nc = {nc:d})\")\n",
    "                    fake_titles.append(txt0) # left: wrong\n",
    "                    real_titles.append(txt1) # right: correct\n",
    "            except:\n",
    "                # shouldn't occur, just skip and continue if it occurs\n",
    "                print(\"error converting nc\")\n",
    "        n += 1\n",
    "        time.sleep(1)  # wait a sec, just in case...\n",
    "    #input(\"finished - quit?\")\n",
    "    br.quit()\n",
    "    print(\"browser closed.\")\n",
    "\n",
    "    # review results\n",
    "    if verbose:\n",
    "        print(\"\\n[+] Real titles\")\n",
    "        for i, title in enumerate(real_titles):\n",
    "            print(f\"\\n#{i:d}\\n{title:s}\")\n",
    "        print(\"\\n[+] Fake titles\")\n",
    "        for i, title in enumerate(fake_titles):\n",
    "            print(f\"\\n#{i:d}\\n{title:s}\")\n",
    "    \n",
    "    # save\n",
    "    f_out = f\"data/training_data.pkl\"\n",
    "    d = {'real' : real_titles, 'fake' : fake_titles}\n",
    "    with open(f_out, \"wb\") as fp:\n",
    "        pickle.dump(d, fp, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    # for processing further down\n",
    "    return real_titles, fake_titles\n",
    "\n",
    "real, fake = download(n_total=10, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load standard training data set\n",
    "If you haven't downloaded your own training data set, you can work with the standard training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded n=1000 real and n=1000 fake samples.\n"
     ]
    }
   ],
   "source": [
    "def reload(filename):\n",
    "    \"\"\"\n",
    "    re-load and analyze samples\n",
    "    \"\"\"\n",
    "    with open(filename, \"rb\") as fp:\n",
    "        d = pickle.load(fp, encoding='latin1')\n",
    "    real = d['real']\n",
    "    fake = d['fake']\n",
    "    print(f\"Loaded n={len(real):d} real and n={len(fake):d} fake samples.\")\n",
    "    return real, fake\n",
    "\n",
    "f_data = f\"data/training_data_std.pkl\"  # 1000 titles each\n",
    "real, fake = reload(f_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "To better understand the problem, let's have a look at a few titles. Most people have difficulties deciding which titles stem from real papers and which were made from the context-free grammar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some real (arXiv) examples: \n",
      "==============================\n",
      "#0: Exact Effective Action for (1+1 Dimensional) Fermions in an Abelian Background at Finite Temperature\n",
      "#1: Four Quark Cn - Nbar Cbar States in U(12)-Scheme and X(3872)/Y(3940)\n",
      "#2: A Heavy Higgs and a Light Sneutrino NLSP in the MSSM With Enhanced SU(2) D-terms\n",
      "#3: Exact Analytic Two-loop Expressions for Some QCD Observables in the Time-like Region\n",
      "#4: Lattice Ising Model in a Field: E$_8$ Scattering Theory\n",
      "\n",
      "Some fake (snarXiv) examples: \n",
      "==============================\n",
      "#0: On Invertible QED_3\n",
      "#1: Anomaly Matching in Deformed QFTs\n",
      "#2: The Multi-field Solution to the LHC Inverse Problem From Inflaton Models (Including the Lithium Problem)\n",
      "#3: The Holographic Entanglement of Purification of De Sitter Space in a Nonperturbative Nonperturbative Twisted QFT\n",
      "#4: Models of Ghosts in Causality\n"
     ]
    }
   ],
   "source": [
    "print(\"Some real (arXiv) examples: \\n\" + 30*\"=\")\n",
    "for i, r in enumerate(real[:5]): print(f\"#{i:d}: {r.strip():s}\", end=\"\\n\")\n",
    "print(\"\\nSome fake (snarXiv) examples: \\n\" + 30*\"=\")\n",
    "for i, f in enumerate(fake[:5]): print(f\"#{i:d}: {f.strip():s}\", end=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text pre-processing\n",
    "For NLP tasks, text is usually pre-processed. Common pre-processing steps involve:\n",
    "- removal of punctuation (e.g.: ,.;!?)\n",
    "- stemming (insert link)\n",
    "\n",
    "In our case, we will just apply a very basic pre-processing:\n",
    "1. strip trailing \"\\n\" characters\n",
    "2. replace \"blank-dash-blank\" by \"dash\", e.g. \"Quark Cn - Nbar Cbar States\" => \"Quark Cn-Nbar Cbar States\"\n",
    "3. replace \"blank-arrow-blank\" by \"arrow\", e.g. \"the B -> X_s Gamma Matrix\" => \"the B->X_s Gamma Matrix\"\n",
    "4. convert all expressions to lowercase\n",
    "\n",
    "Points 2. and 3. are necessary to avoid splitting expressions such as \"Cn - Nbar\" into [\"Cn\", \"-\", \"Nbar\"] when titles will be processed by the CountVectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = lambda s: s.strip().replace(\" - \", \"-\").replace(\" -> \", \"->\").lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a bag-of-words (bow) and target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def bow(real, fake):\n",
    "    \"\"\"\n",
    "    Bag Of Words\n",
    "    \"\"\"\n",
    "    all_titles = [preprocess(title) for title in real+fake]\n",
    "    y = np.concatenate( (np.ones(len(real)), np.zeros(len(fake))) ) # target values (real: 1, fake: 0)\n",
    "    return all_titles, y\n",
    "\n",
    "titles, y = bow(real, fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "Do an 80-20 split on the data, retaining 20% for final performance evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #, StratifiedShuffleSplit\n",
    "titles_train, titles_test, y_train, y_test = train_test_split(titles, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizer transform\n",
    "Next, the text data will be transformed to numbers, in order to work with numerical methods such as logistic regression, among others.  \n",
    "\n",
    "**Options**:\n",
    "- CountVectorizer\n",
    "- TfidfVectorizer\n",
    "\n",
    "**Note:** The vectorizer has to be trained on the *complete* data set. If the vectorizer is built on the training data set alone, some words in the testing data set may not be recognized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  2000  words.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "vectorizer = CountVectorizer(max_features=2000)\n",
    "#vectorizer = TfidfVectorizer(max_features=2000)\n",
    "vectorizer.fit(titles) # titles_train\n",
    "print(\"Vocabulary size: \", len(vectorizer.vocabulary_), \" words.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply vectorizer to train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and test data vectorized. (1600, 2000) (400, 2000)\n"
     ]
    }
   ],
   "source": [
    "X_train = vectorizer.transform(titles_train)\n",
    "X_test = vectorizer.transform(titles_test)\n",
    "print(\"Training and test data vectorized.\", X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Side note:** What does the vectorizer do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary dict:  {'this': 4, 'book': 0, 'is': 1, 'not': 3, 'my': 2}\n",
      "\n",
      "Sentence transformed to array:\n",
      " [[0 0 0 0 1]\n",
      " [1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 1 0 0]\n",
      " [1 0 0 0 0]]\n",
      "\n",
      "Explanation: \n",
      "'this' encoded as a vector:  [0 0 0 0 1]  because voc['this'] =  4\n",
      "'book' encoded as a vector:  [1 0 0 0 0]  because voc['book'] =  0\n",
      "'is' encoded as a vector:  [0 1 0 0 0]  because voc['is'] =  1\n",
      "'not' encoded as a vector:  [0 0 0 1 0]  because voc['not'] =  3\n",
      "'my' encoded as a vector:  [0 0 1 0 0]  because voc['my'] =  2\n",
      "'book' encoded as a vector:  [1 0 0 0 0]  because voc['book'] =  0\n"
     ]
    }
   ],
   "source": [
    "# count vectorizer\n",
    "X = \"this book is not my book\".split()\n",
    "vec2 = CountVectorizer().fit(X)\n",
    "voc = vec2.vocabulary_\n",
    "print(\"Vocabulary dict: \", voc) # <class 'dict'> 2358\n",
    "Y = vec2.transform(X).toarray()\n",
    "print(\"\\nSentence transformed to array:\\n\", Y)\n",
    "print(\"\\nExplanation: \")\n",
    "for i, x in enumerate(X):\n",
    "    print(f\"'{x:s}' encoded as a vector: \", Y[i,:], f\" because voc['{x:s}'] = \", voc[x])\n",
    "del X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First ML approach: logistic regression\n",
    "\n",
    "Data and target labels are prepared, time to train a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     12,
     18
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression accuracy: 90.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)\n",
    "print(f\"{clf.__class__.__name__:s} accuracy: {score:.1%}\")\n",
    "\n",
    "#pred_ = clf.predict(X_test)\n",
    "#for a, b in zip(y_test, pred_):\n",
    "#    print(f\"{a:.0f}|{b:.0f}\")\n",
    "\n",
    "save_vectorizer = False\n",
    "if save_vectorizer:\n",
    "    f_vect = \"data/sklearn_snarxiv_vectorizer.pkl\"\n",
    "    with open(f_vect, 'wb') as fp:\n",
    "        pickle.dump(vectorizer, fp)\n",
    "\n",
    "save_classifier = False\n",
    "if save_classifier:\n",
    "    f_model = \"data/sklearn_snarxiv_model.pkl\"\n",
    "    with open(f_model, 'wb') as fp:\n",
    "        pickle.dump(clf, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "To test the robustness of this results, do a few runs of cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.8625 0.8375 0.8375 0.8625 0.8125]\n",
      "Mean score: 0.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "n_cv = 5\n",
    "scores = cross_val_score(clf, X_test, y_test, cv=5)\n",
    "print(\"Scores: \", scores)\n",
    "print(f\"Mean score: {np.mean(scores):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other classifiers\n",
    "A few other scikit-learn classifiers to play with..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier accuracy: 92.0%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#clf = RandomForestClassifier(n_estimators=100) # 88.8%\n",
    "\n",
    "#from sklearn.ensemble import AdaBoostClassifier\n",
    "#clf = AdaBoostClassifier() # 78.5%\n",
    "\n",
    "#from sklearn.ensemble import GradientBoostingClassifier\n",
    "#clf = GradientBoostingClassifier()\n",
    "\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#clf = DecisionTreeClassifier() # 79.8%\n",
    "\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#clf = KNeighborsClassifier(3) # 78.5%\n",
    "\n",
    "#from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "#clf = SVC(kernel=\"rbf\", C=3, probability=True)\n",
    "\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#clf = GaussianNB() # needs X_train.toarray(), X_test.toarray()\n",
    "\n",
    "#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "#clf = LinearDiscriminantAnalysis() # needs X_train.toarray(), X_test.toarray()\n",
    "\n",
    "#from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "#clf = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(hidden_layer_sizes=(10,), alpha=1e-4, max_iter=300, random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)\n",
    "print(f\"{clf.__class__.__name__:s} accuracy: {score:.1%}\")\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.plot(clf.loss_curve_, '-ok')\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.xlabel(\"loss\")\n",
    "plt.title(\"MLP loss function\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search optimization of hyperparameters\n",
    "\n",
    "Do a gridsearch to find optimum hyperparameter values, save the results.  \n",
    "This code block can take a while to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "'''\n",
    "gs = GridSearchCV(\n",
    "    MLPClassifier(random_state=1, max_iter=300),\n",
    "    param_grid={\n",
    "        \"hidden_layer_sizes\": [10, 25, 50, 100],\n",
    "        \"alpha\": [0.0001, 0.001, 0.01, 0.1],\n",
    "    },\n",
    "    return_train_score=True,\n",
    ")\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.cv_results_)\n",
    "f_gs = \"data/MLP_gridsearch_results_.pkl\"\n",
    "with open(f_gs, 'wb') as fp: pickle.dump(gs.cv_results_, fp)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-eebdcac179ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mf_gs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/MLP_gridsearch_results.pkl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_gs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmlp_gs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp_gs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#print(results.head())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m scores_matrix = results.pivot(\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "f_gs = \"data/MLP_gridsearch_results.pkl\"\n",
    "with open(f_gs, \"rb\") as fp: mlp_gs = pickle.load(fp, encoding='latin1')\n",
    "results = pd.DataFrame.from_dict(mlp_gs)\n",
    "#print(results.head())\n",
    "scores_matrix = results.pivot(\n",
    "    index=\"param_hidden_layer_sizes\", columns=\"param_alpha\", values=\"mean_test_score\"\n",
    ")\n",
    "#print(scores_matrix)\n",
    "\n",
    "hl_sizes = [10, 25, 50, 100]\n",
    "alphas = [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "# heatmap adapted from: \n",
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_successive_halving_heatmap.html\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = plt.gca()\n",
    "ax.imshow(scores_matrix)\n",
    "ax.set_xticks(np.arange(len(alphas)))\n",
    "ax.set_xticklabels([\"{:.0E}\".format(x) for x in alphas])\n",
    "ax.set_xlabel(\"alpha\", fontsize=15)\n",
    "ax.set_yticks(np.arange(len(hl_sizes)))\n",
    "ax.set_yticklabels([\"{:.0f}\".format(x) for x in hl_sizes])\n",
    "ax.set_ylabel(\"hl size\", fontsize=15)\n",
    "for i in range(len(alphas)):\n",
    "    for j in range(len(hl_sizes)):\n",
    "        t = f\"{scores_matrix.loc[hl_sizes[j],alphas[i]]:.3f}\"\n",
    "        ax.text(j, i, t, ha=\"center\", va=\"center\", color=\"w\", fontsize=16)\n",
    "plt.title(\"GridSearchCV\", fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the classifier online\n",
    "\n",
    "On our test data set, we got a pretty nice classification accuracy.  \n",
    "It would be much nicer to see the classifier perform online, so let's do that. Again, we will use Selenium to interact with the [snarXiv-vs-arXiv](http://snarxiv.org/vs-arxiv/) website automatically.  \n",
    "Sit back and enjoy the game!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def apply_model(vectorizer=None, clf=None, n_total=1, verbose=False):\n",
    "    if not vectorizer:\n",
    "        # re-load vectorizer and model\n",
    "        f_vect = \"sklearn_snarxiv_vectorizer.pkl\"\n",
    "        with open(f_vect, 'rb') as fp:\n",
    "            vectorizer = pickle.load(fp)\n",
    "\n",
    "    if not clf:\n",
    "        f_model = \"sklearn_snarxiv_model.pkl\"\n",
    "        with open(f_model, 'rb') as fp:\n",
    "            clf = pickle.load(fp)\n",
    "\n",
    "    # connect to snarXiv\n",
    "    options = webdriver.FirefoxOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument('--ignore-certificate-errors')\n",
    "    options.add_argument(\"--test-type\")\n",
    "    profile = webdriver.FirefoxProfile()\n",
    "    br = webdriver.Firefox(profile)\n",
    "    br.get(\"http://snarxiv.org/vs-arxiv\")\n",
    "\n",
    "    #n_total = 1000 # number of trials\n",
    "    n = 0 # counter\n",
    "    n_correct = nc = 0 # current number of correct answers\n",
    "\n",
    "    # collect titles for future training\n",
    "    while n <= n_total:\n",
    "        if verbose: print(f\"[+] Trial: {n:d}/{n_total:d}\")\n",
    "        # get DOM elements\n",
    "        c0 = br.find_element_by_class_name('corner-0')\n",
    "        h0 = c0.find_element_by_tag_name('h1')\n",
    "        a0 = h0.find_element_by_tag_name('a')\n",
    "        txt0 = a0.text.replace(\"Is this one real?\", \"\") # left title\n",
    "        c1 = br.find_element_by_class_name('corner-1')\n",
    "        h1 = c1.find_element_by_tag_name('h1')\n",
    "        a1 = h1.find_element_by_tag_name('a')\n",
    "        txt1 = a1.text.replace(\"Is this one real?\", \"\") # right title\n",
    "        # use the same preprocessing as during training\n",
    "        txt0 = preprocess(txt0)\n",
    "        txt1 = preprocess(txt1)\n",
    "        # transform title\n",
    "        x0 = vectorizer.transform([txt0])\n",
    "        x1 = vectorizer.transform([txt1])\n",
    "        # get classifier predictions\n",
    "        pred0 = clf.predict(x0)\n",
    "        pred1 = clf.predict(x1)\n",
    "        #print(\"Predictions: \", pred0, pred1)\n",
    "        # click the option with the higher classifier score\n",
    "        if pred0 >= pred1:\n",
    "            a0.click()\n",
    "        else:\n",
    "            a1.click()\n",
    "        # number of correct guesses\n",
    "        if n > 0:\n",
    "            s_nc = br.find_element_by_id('correct').text\n",
    "            try:\n",
    "                nc = int(s_nc) # string => int\n",
    "                if verbose: print(f\"\\tcorrect (nc = {nc:d})\")\n",
    "            except:\n",
    "                if verbose: print(\"error converting nc\")\n",
    "        n += 1\n",
    "        time.sleep(1)  # wait a sec, just in case...\n",
    "    print(f\"Classifier achieved {100.*nc/n:.1f}% accuracy online.\")\n",
    "    input(\"finished - quit?\")\n",
    "    br.quit()\n",
    "    print(\"browser closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_model(vectorizer, clf, n_total=30, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof of concept\n",
    "Watch the classifier at work  \n",
    "<br>\n",
    "<video src=\"pics/snarxiv_MLPonline_test_crop.mp4\" width=600 controls=true>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final note:\n",
    "There is an easy way to get *all* answers right. The snarXiv-vs-arXiv web app sends a GET request to the `fight.py` server-side app. The response to this GET request contains the correct answer. As shown below, only the \"Time-reversal...\" title has a valid arXiv link (white arrow).\n",
    "\n",
    "<img src=\"pics/network_screenshot2.png\" width=1000 controls=true>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
